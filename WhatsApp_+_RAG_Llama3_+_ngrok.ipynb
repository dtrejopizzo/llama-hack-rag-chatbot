{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kkE_CpnJb9hx"
      },
      "outputs": [],
      "source": [
        "!pip install langchain replicate flask requests uvicorn gunicorn langchain_community chromadb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Copyright (c) Meta Platforms, Inc. and affiliates.\n",
        "# This software may be used and distributed according to the terms of the Llama 3 Community License Agreement.\n",
        "\n",
        "!pip install flask pyngrok langchain chromadb sentence-transformers replicate\n",
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip ngrok-stable-linux-amd64.zip\n",
        "\n",
        "import os\n",
        "import requests\n",
        "import json\n",
        "from flask import Flask, request\n",
        "from langchain.llms import Replicate\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.document_loaders import TextLoader\n",
        "from pyngrok import ngrok\n",
        "\n",
        "class WhatsAppClient:\n",
        "    API_URL = \"https://graph.facebook.com/v21.0/\"\n",
        "    WHATSAPP_API_TOKEN = \"your_token\"\n",
        "    WHATSAPP_CLOUD_NUMBER_ID = \"number\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.headers = {\n",
        "            \"Authorization\": f\"Bearer {self.WHATSAPP_API_TOKEN}\",\n",
        "            \"Content-Type\": \"application/json\",\n",
        "        }\n",
        "        self.API_URL = self.API_URL + self.WHATSAPP_CLOUD_NUMBER_ID\n",
        "\n",
        "    def send_text_message(self, message, phone_number):\n",
        "        payload = {\n",
        "            \"messaging_product\": 'whatsapp',\n",
        "            \"to\": phone_number,\n",
        "            \"type\": \"text\",\n",
        "            \"text\": {\n",
        "                \"preview_url\": False,\n",
        "                \"body\": message\n",
        "            }\n",
        "        }\n",
        "        response = requests.post(f\"{self.API_URL}/messages\", json=payload, headers=self.headers)\n",
        "        print(response.status_code)\n",
        "        assert response.status_code == 200, \"Error sending message\"\n",
        "        return response.status_code\n",
        "\n",
        "# Set up Llama 3 model\n",
        "os.environ[\"REPLICATE_API_TOKEN\"] = \"your_token\"\n",
        "llama3_8b_chat = \"meta/meta-llama-3-8b-instruct\"\n",
        "\n",
        "llm = Replicate(\n",
        "    model=llama3_8b_chat,\n",
        "    model_kwargs={\"temperature\": 0.0, \"top_p\": 1, \"max_new_tokens\": 500}\n",
        ")\n",
        "\n",
        "# Set up RAG components\n",
        "embeddings = HuggingFaceEmbeddings()\n",
        "\n",
        "# Load and process your knowledge base\n",
        "# For this example, we'll create a simple text file\n",
        "with open(\"knowledge_base.txt\", \"w\") as f:\n",
        "    f.write(\"This is a sample knowledge base for the RAG system.\\n\")\n",
        "    f.write(\"It contains information about various topics.\\n\")\n",
        "    f.write(\"The RAG system will use this information to provide context-aware responses.\\n\")\n",
        "\n",
        "loader = TextLoader(\"knowledge_base.txt\")\n",
        "documents = loader.load()\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "texts = text_splitter.split_documents(documents)\n",
        "\n",
        "# Create vector store\n",
        "vectorstore = Chroma.from_documents(texts, embeddings)\n",
        "\n",
        "# Create RetrievalQA chain\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=vectorstore.as_retriever(search_kwargs={\"k\": 3}),\n",
        "    return_source_documents=True,\n",
        ")\n",
        "\n",
        "client = WhatsAppClient()\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route(\"/\")\n",
        "def hello_llama():\n",
        "    return \"<p>Hello Llama 3 RAG</p>\"\n",
        "\n",
        "@app.route('/msgrcvd', methods=['POST', 'GET'])\n",
        "def msgrcvd():\n",
        "    message = request.args.get('message')\n",
        "\n",
        "    # Use the RAG system to generate a response\n",
        "    result = qa_chain({\"query\": message})\n",
        "    answer = result['result']\n",
        "\n",
        "    print(\"User message:\", message)\n",
        "    print(\"Bot response:\", answer)\n",
        "\n",
        "    client.send_text_message(answer, \"<your phone number>\")\n",
        "    return message + \"<p/>\" + answer\n",
        "\n",
        "# Set up ngrok\n",
        "ngrok.set_auth_token(\"your_token\")  # Replace with your ngrok auth token\n",
        "public_url = ngrok.connect(5000)\n",
        "print(f\" * ngrok tunnel \\\"{public_url}\\\" -> \\\"http://127.0.0.1:5000/\\\"\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    app.run()"
      ],
      "metadata": {
        "id": "phV40cS-cDyw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}